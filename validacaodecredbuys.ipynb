{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2nPIB4NixCk",
        "outputId": "97a777cd-3204-4436-8afd-3281e278276c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "                              AVALIA√á√ÉO COMPLETA DO MODELO\n",
            "====================================================================================================\n",
            "\n",
            "Dataset carregado: 1759 exemplos, 10 features\n",
            "Target: Class\n",
            "\n",
            "====================================================================================================\n",
            "AN√ÅLISE DE DESBALANCEAMENTO\n",
            "====================================================================================================\n",
            "\n",
            "Distribui√ß√£o Original das Classes:\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ   Classe    ‚îÇ  Exemplos  ‚îÇ Propor√ß√£o % ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ   Classe 0  ‚îÇ    1267    ‚îÇ    72.03%   ‚îÇ\n",
            "‚îÇ   Classe 1  ‚îÇ     492    ‚îÇ    27.97%   ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "Raz√£o de Desbalanceamento: 2.58:1\n",
            "N√≠vel de Desbalanceamento: SEVERO\n",
            "\n",
            " IMPACTO ESPERADO DO DESBALANCEAMENTO:\n",
            "   ‚Ä¢ Modelo pode ter vi√©s para a classe majorit√°ria\n",
            "   ‚Ä¢ M√©tricas como Acur√°cia podem ser enganosas\n",
            "   ‚Ä¢ Classe minorit√°ria pode ter baixo Recall\n",
            "   ‚Ä¢ T√©cnicas de balanceamento s√£o NECESS√ÅRIAS\n",
            "\n",
            "====================================================================================================\n",
            "COMPARA√á√ÉO: SEM vs COM BALANCEAMENTO\n",
            "====================================================================================================\n",
            "\n",
            "Testando SEM balanceamento (Baseline)...\n",
            "   ‚úì Baseline - Macro F1: 0.9372, Acur√°cia: 0.9517\n",
            "\n",
            "Testando COM SMOTE...\n",
            "   ‚úì SMOTE - Macro F1: 0.9308, Acur√°cia: 0.9460\n",
            "\n",
            "Testando COM ADASYN...\n",
            "   ‚úì ADASYN - Macro F1: 0.9146, Acur√°cia: 0.9318\n",
            "\n",
            "Testando COM SMOTE + Tomek Links...\n",
            "   ‚úì SMOTE+Tomek - Macro F1: 0.9415, Acur√°cia: 0.9545\n",
            "\n",
            "Testando COM Under-Sampling...\n",
            "   ‚úì Under-Sampling - Macro F1: 0.9250, Acur√°cia: 0.9403\n",
            "\n",
            "====================================================================================================\n",
            "TABELA COMPARATIVA DE T√âCNICAS\n",
            "====================================================================================================\n",
            "\n",
            "          T√©cnica  Acur√°cia  Macro F1-Score  Weighted F1-Score  Macro Precision  Macro Recall\n",
            "SEM Balanceamento    0.9517          0.9372             0.9506           0.9601        0.9195\n",
            "            SMOTE    0.9460          0.9308             0.9452           0.9453        0.9187\n",
            "           ADASYN    0.9318          0.9146             0.9316           0.9173        0.9120\n",
            "      SMOTE+Tomek    0.9545          0.9415             0.9538           0.9583        0.9278\n",
            "   Under-Sampling    0.9403          0.9250             0.9401           0.9293        0.9211\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "MELHOR T√âCNICA: SMOTE+Tomek\n",
            "   Macro F1-Score: 0.9415\n",
            "   Melhoria sobre Baseline: +0.46%\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "\n",
            " Gerando visualiza√ß√µes...\n",
            "   ‚úì Gr√°ficos salvos em: comparacao_tecnicas.png\n",
            "\n",
            "üìä Gerando matrizes de confus√£o...\n",
            "   ‚úì Matrizes de confus√£o salvas em: matrizes_confusao.png\n",
            "\n",
            "====================================================================================================\n",
            "AN√ÅLISE DETALHADA POR CLASSE\n",
            "====================================================================================================\n",
            "\n",
            "Compara√ß√£o: BASELINE vs SMOTE+Tomek\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ Classe  ‚îÇ      SEM Balanceamento       ‚îÇ           SMOTE+Tomek            ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ         ‚îÇ  Prec   Recall   F1-Score    ‚îÇ  Prec   Recall   F1-Score    ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Classe 0 ‚îÇ  0.944   0.992    0.967     ‚îÇ  0.951   0.988    0.969     ‚îÇ\n",
            "‚îÇ Classe 1 ‚îÇ  0.976   0.847    0.907     ‚îÇ  0.966   0.867    0.914     ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "MELHORIAS POR CLASSE:\n",
            "\n",
            "   Classe 0: ^ +0.18% (de 0.9674 para 0.9691)\n",
            "   Classe 1: ^ +0.76% (de 0.9071 para 0.9140)\n",
            "\n",
            "Gerando relat√≥rio final...\n",
            "   ‚úì Relat√≥rio salvo em: RELATORIO_AVALIACAO.txt\n",
            "\n",
            "====================================================================================================\n",
            "AVALIA√á√ÉO COMPLETA CONCLU√çDA COM SUCESSO!\n",
            "====================================================================================================\n",
            "\n",
            "Arquivos gerados:\n",
            "   ‚Ä¢ RELATORIO_AVALIACAO.txt - Relat√≥rio completo\n",
            "   ‚Ä¢ comparacao_tecnicas.png - Gr√°ficos comparativos\n",
            "   ‚Ä¢ matrizes_confusao.png   - Matrizes de confus√£o\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix,\n",
        "    f1_score, accuracy_score, precision_score, recall_score,\n",
        "    roc_auc_score, roc_curve\n",
        ")\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTETomek\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "class AvaliacaoCompleta:\n",
        "    \"\"\"Classe para avalia√ß√£o completa do modelo com an√°lise de desbalanceamento\"\"\"\n",
        "\n",
        "    def __init__(self, filepath, target_column=None, features_selecionadas=None):\n",
        "        \"\"\"\n",
        "        Inicializa a avalia√ß√£o\n",
        "\n",
        "        Args:\n",
        "            filepath: Caminho para o arquivo de dados\n",
        "            target_column: Nome da coluna target\n",
        "            features_selecionadas: Lista de features selecionadas\n",
        "        \"\"\"\n",
        "        print(\"=\" * 100)\n",
        "        print(\" \" * 30 + \"AVALIA√á√ÉO COMPLETA DO MODELO\")\n",
        "        print(\"=\" * 100 + \"\\n\")\n",
        "\n",
        "        # Carregar dados\n",
        "        if filepath.endswith('.csv'):\n",
        "            self.df = pd.read_csv(filepath)\n",
        "        else:\n",
        "            self.df = pd.read_excel(filepath)\n",
        "\n",
        "        # Definir target\n",
        "        if target_column is None:\n",
        "            target_column = self.df.columns[-1]\n",
        "\n",
        "        self.target_column = target_column\n",
        "\n",
        "        # Selecionar features\n",
        "        if features_selecionadas is None:\n",
        "            self.X = self.df.drop(columns=[target_column])\n",
        "        else:\n",
        "            self.X = self.df[features_selecionadas]\n",
        "\n",
        "        self.y = self.df[target_column]\n",
        "\n",
        "        print(f\"Dataset carregado: {self.df.shape[0]} exemplos, {self.X.shape[1]} features\")\n",
        "        print(f\"Target: {target_column}\")\n",
        "\n",
        "        # Analisar desbalanceamento\n",
        "        self._analisar_desbalanceamento()\n",
        "\n",
        "    def _analisar_desbalanceamento(self):\n",
        "        \"\"\"Analisa o desbalanceamento das classes\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 100)\n",
        "        print(\"AN√ÅLISE DE DESBALANCEAMENTO\")\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "        contagem = self.y.value_counts().sort_index()\n",
        "        proporcoes = self.y.value_counts(normalize=True).sort_index() * 100\n",
        "\n",
        "        print(\"\\nDistribui√ß√£o Original das Classes:\\n\")\n",
        "        print(\"‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
        "        print(\"‚îÇ   Classe    ‚îÇ  Exemplos  ‚îÇ Propor√ß√£o % ‚îÇ\")\n",
        "        print(\"‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\")\n",
        "        for classe in contagem.index:\n",
        "            count = contagem[classe]\n",
        "            prop = proporcoes[classe]\n",
        "            print(f\"‚îÇ   Classe {classe}  ‚îÇ   {count:5d}    ‚îÇ    {prop:5.2f}%   ‚îÇ\")\n",
        "        print(\"‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
        "\n",
        "        # Calcular raz√£o\n",
        "        razao = contagem.max() / contagem.min()\n",
        "        self.razao_desbalanceamento = razao\n",
        "\n",
        "        print(f\"\\nRaz√£o de Desbalanceamento: {razao:.2f}:1\")\n",
        "\n",
        "        if razao > 2:\n",
        "            nivel = \"SEVERO\"\n",
        "        elif razao > 1.5:\n",
        "            nivel = \"MODERADO\"\n",
        "        else:\n",
        "            nivel = \"BAIXO\"\n",
        "\n",
        "\n",
        "        print(f\"N√≠vel de Desbalanceamento: {nivel}\")\n",
        "\n",
        "        if razao > 1.5:\n",
        "            print(\"\\n IMPACTO ESPERADO DO DESBALANCEAMENTO:\")\n",
        "            print(\"   ‚Ä¢ Modelo pode ter vi√©s para a classe majorit√°ria\")\n",
        "            print(\"   ‚Ä¢ M√©tricas como Acur√°cia podem ser enganosas\")\n",
        "            print(\"   ‚Ä¢ Classe minorit√°ria pode ter baixo Recall\")\n",
        "            print(\"   ‚Ä¢ T√©cnicas de balanceamento s√£o NECESS√ÅRIAS\")\n",
        "\n",
        "    def comparar_tecnicas_balanceamento(self, modelo_nome='Random Forest',\n",
        "                                       features_selecionadas=None, cv_folds=5):\n",
        "        \"\"\"\n",
        "        Compara o desempenho do modelo SEM e COM diferentes t√©cnicas de balanceamento\n",
        "\n",
        "        Args:\n",
        "            modelo_nome: Nome do modelo a usar\n",
        "            features_selecionadas: Lista de features\n",
        "            cv_folds: N√∫mero de folds\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\" * 100)\n",
        "        print(\"COMPARA√á√ÉO: SEM vs COM BALANCEAMENTO\")\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "        # Preparar dados\n",
        "        if features_selecionadas is None:\n",
        "            X = self.X\n",
        "        else:\n",
        "            X = self.X[features_selecionadas]\n",
        "\n",
        "        # Split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, self.y, test_size=0.2, random_state=42, stratify=self.y\n",
        "        )\n",
        "\n",
        "        # Padronizar\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # Selecionar modelo\n",
        "        if modelo_nome == 'Random Forest':\n",
        "            modelo_base = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "        elif modelo_nome == 'Gradient Boosting':\n",
        "            modelo_base = GradientBoostingClassifier(n_estimators=200, random_state=42)\n",
        "        else:\n",
        "            modelo_base = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "        resultados = {}\n",
        "\n",
        "        # 1. SEM BALANCEAMENTO (BASELINE)\n",
        "        print(\"\\nTestando SEM balanceamento (Baseline)...\")\n",
        "        modelo = modelo_base.__class__(**modelo_base.get_params())\n",
        "        modelo.fit(X_train_scaled, y_train)\n",
        "        y_pred = modelo.predict(X_test_scaled)\n",
        "\n",
        "        resultados['SEM Balanceamento'] = self._calcular_metricas(y_test, y_pred, \"Baseline\")\n",
        "\n",
        "        # 2. COM SMOTE\n",
        "        print(\"\\nTestando COM SMOTE...\")\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_smote, y_smote = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "        modelo = modelo_base.__class__(**modelo_base.get_params())\n",
        "        modelo.fit(X_smote, y_smote)\n",
        "        y_pred = modelo.predict(X_test_scaled)\n",
        "\n",
        "        resultados['SMOTE'] = self._calcular_metricas(y_test, y_pred, \"SMOTE\")\n",
        "\n",
        "        # 3. COM ADASYN\n",
        "        print(\"\\nTestando COM ADASYN...\")\n",
        "        try:\n",
        "            adasyn = ADASYN(random_state=42)\n",
        "            X_adasyn, y_adasyn = adasyn.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "            modelo = modelo_base.__class__(**modelo_base.get_params())\n",
        "            modelo.fit(X_adasyn, y_adasyn)\n",
        "            y_pred = modelo.predict(X_test_scaled)\n",
        "\n",
        "            resultados['ADASYN'] = self._calcular_metricas(y_test, y_pred, \"ADASYN\")\n",
        "        except:\n",
        "            print(\"ADASYN falhou (poss√≠vel falta de vizinhos)\")\n",
        "            resultados['ADASYN'] = None\n",
        "\n",
        "        # 4. COM SMOTE + Tomek\n",
        "        print(\"\\nTestando COM SMOTE + Tomek Links...\")\n",
        "        smotetomek = SMOTETomek(random_state=42)\n",
        "        X_st, y_st = smotetomek.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "        modelo = modelo_base.__class__(**modelo_base.get_params())\n",
        "        modelo.fit(X_st, y_st)\n",
        "        y_pred = modelo.predict(X_test_scaled)\n",
        "\n",
        "        resultados['SMOTE+Tomek'] = self._calcular_metricas(y_test, y_pred, \"SMOTE+Tomek\")\n",
        "\n",
        "        # 5. COM Under-sampling\n",
        "        print(\"\\nTestando COM Under-Sampling...\")\n",
        "        under = RandomUnderSampler(random_state=42)\n",
        "        X_under, y_under = under.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "        modelo = modelo_base.__class__(**modelo_base.get_params())\n",
        "        modelo.fit(X_under, y_under)\n",
        "        y_pred = modelo.predict(X_test_scaled)\n",
        "\n",
        "        resultados['Under-Sampling'] = self._calcular_metricas(y_test, y_pred, \"Under-Sampling\")\n",
        "\n",
        "        self.resultados_comparacao = resultados\n",
        "        self.X_test = X_test_scaled\n",
        "        self.y_test = y_test\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    def _calcular_metricas(self, y_true, y_pred, nome_tecnica):\n",
        "        \"\"\"Calcula todas as m√©tricas necess√°rias\"\"\"\n",
        "\n",
        "        metricas = {\n",
        "            'Acur√°cia': accuracy_score(y_true, y_pred),\n",
        "            'Macro F1-Score': f1_score(y_true, y_pred, average='macro'),\n",
        "            'Weighted F1-Score': f1_score(y_true, y_pred, average='weighted'),\n",
        "            'Macro Precision': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
        "            'Macro Recall': recall_score(y_true, y_pred, average='macro'),\n",
        "            'Confusion Matrix': confusion_matrix(y_true, y_pred)\n",
        "        }\n",
        "\n",
        "        # M√©tricas por classe\n",
        "        report = classification_report(y_true, y_pred, output_dict=True)\n",
        "        metricas['Report'] = report\n",
        "\n",
        "        print(f\"   ‚úì {nome_tecnica} - Macro F1: {metricas['Macro F1-Score']:.4f}, Acur√°cia: {metricas['Acur√°cia']:.4f}\")\n",
        "\n",
        "        return metricas\n",
        "\n",
        "    def gerar_tabela_comparativa(self):\n",
        "        \"\"\"Gera tabela comparativa das t√©cnicas\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 100)\n",
        "        print(\"TABELA COMPARATIVA DE T√âCNICAS\")\n",
        "        print(\"=\" * 100 + \"\\n\")\n",
        "\n",
        "        # Criar DataFrame\n",
        "        data = []\n",
        "        for tecnica, metricas in self.resultados_comparacao.items():\n",
        "            if metricas is not None:\n",
        "                data.append({\n",
        "                    'T√©cnica': tecnica,\n",
        "                    'Acur√°cia': metricas['Acur√°cia'],\n",
        "                    'Macro F1-Score': metricas['Macro F1-Score'],\n",
        "                    'Weighted F1-Score': metricas['Weighted F1-Score'],\n",
        "                    'Macro Precision': metricas['Macro Precision'],\n",
        "                    'Macro Recall': metricas['Macro Recall']\n",
        "                })\n",
        "\n",
        "        df_comp = pd.DataFrame(data)\n",
        "        df_comp = df_comp.round(4)\n",
        "\n",
        "        print(df_comp.to_string(index=False))\n",
        "\n",
        "        # Identificar melhor t√©cnica\n",
        "        melhor_idx = df_comp['Macro F1-Score'].idxmax()\n",
        "        melhor_tecnica = df_comp.iloc[melhor_idx]['T√©cnica']\n",
        "        melhor_f1 = df_comp.iloc[melhor_idx]['Macro F1-Score']\n",
        "\n",
        "        baseline_f1 = df_comp[df_comp['T√©cnica'] == 'SEM Balanceamento']['Macro F1-Score'].values[0]\n",
        "        melhoria = ((melhor_f1 - baseline_f1) / baseline_f1) * 100\n",
        "\n",
        "        print(\"\\n\" + \"‚îÄ\" * 100)\n",
        "        print(f\"MELHOR T√âCNICA: {melhor_tecnica}\")\n",
        "        print(f\"   Macro F1-Score: {melhor_f1:.4f}\")\n",
        "        print(f\"   Melhoria sobre Baseline: +{melhoria:.2f}%\")\n",
        "        print(\"‚îÄ\" * 100)\n",
        "\n",
        "        self.df_comparacao = df_comp\n",
        "        self.melhor_tecnica = melhor_tecnica\n",
        "\n",
        "        return df_comp\n",
        "\n",
        "    def visualizar_comparacao(self, output_file='comparacao_tecnicas.png'):\n",
        "        \"\"\"Cria visualiza√ß√µes comparativas\"\"\"\n",
        "        print(f\"\\n Gerando visualiza√ß√µes...\")\n",
        "\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "        fig.suptitle('Compara√ß√£o de T√©cnicas de Balanceamento',\n",
        "                     fontsize=18, fontweight='bold', y=0.995)\n",
        "\n",
        "        # 1. Acur√°cia\n",
        "        ax = axes[0, 0]\n",
        "        self.df_comparacao.plot(x='T√©cnica', y='Acur√°cia', kind='bar',\n",
        "                                ax=ax, color='steelblue', legend=False)\n",
        "        ax.set_title('Acur√°cia', fontsize=14, fontweight='bold')\n",
        "        ax.set_ylabel('Score', fontsize=12)\n",
        "        ax.set_xlabel('')\n",
        "        ax.set_ylim([0.85, 1.0])\n",
        "        ax.grid(axis='y', alpha=0.3)\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # Destacar melhor\n",
        "        melhor_idx = self.df_comparacao['Acur√°cia'].idxmax()\n",
        "        ax.patches[melhor_idx].set_color('gold')\n",
        "        ax.patches[melhor_idx].set_edgecolor('black')\n",
        "        ax.patches[melhor_idx].set_linewidth(3)\n",
        "\n",
        "        # 2. Macro F1-Score\n",
        "        ax = axes[0, 1]\n",
        "        self.df_comparacao.plot(x='T√©cnica', y='Macro F1-Score', kind='bar',\n",
        "                                ax=ax, color='coral', legend=False)\n",
        "        ax.set_title('Macro F1-Score (M√©trica Principal)', fontsize=14, fontweight='bold')\n",
        "        ax.set_ylabel('Score', fontsize=12)\n",
        "        ax.set_xlabel('')\n",
        "        ax.set_ylim([0.85, 1.0])\n",
        "        ax.grid(axis='y', alpha=0.3)\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # Destacar melhor\n",
        "        melhor_idx = self.df_comparacao['Macro F1-Score'].idxmax()\n",
        "        ax.patches[melhor_idx].set_color('gold')\n",
        "        ax.patches[melhor_idx].set_edgecolor('black')\n",
        "        ax.patches[melhor_idx].set_linewidth(3)\n",
        "\n",
        "        # 3. Weighted F1-Score\n",
        "        ax = axes[0, 2]\n",
        "        self.df_comparacao.plot(x='T√©cnica', y='Weighted F1-Score', kind='bar',\n",
        "                                ax=ax, color='mediumseagreen', legend=False)\n",
        "        ax.set_title('Weighted F1-Score', fontsize=14, fontweight='bold')\n",
        "        ax.set_ylabel('Score', fontsize=12)\n",
        "        ax.set_xlabel('')\n",
        "        ax.set_ylim([0.85, 1.0])\n",
        "        ax.grid(axis='y', alpha=0.3)\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # 4. Macro Precision\n",
        "        ax = axes[1, 0]\n",
        "        self.df_comparacao.plot(x='T√©cnica', y='Macro Precision', kind='bar',\n",
        "                                ax=ax, color='plum', legend=False)\n",
        "        ax.set_title('Macro Precision', fontsize=14, fontweight='bold')\n",
        "        ax.set_ylabel('Score', fontsize=12)\n",
        "        ax.set_xlabel('')\n",
        "        ax.set_ylim([0.85, 1.0])\n",
        "        ax.grid(axis='y', alpha=0.3)\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # 5. Macro Recall\n",
        "        ax = axes[1, 1]\n",
        "        self.df_comparacao.plot(x='T√©cnica', y='Macro Recall', kind='bar',\n",
        "                                ax=ax, color='lightsalmon', legend=False)\n",
        "        ax.set_title('Macro Recall', fontsize=14, fontweight='bold')\n",
        "        ax.set_ylabel('Score', fontsize=12)\n",
        "        ax.set_xlabel('')\n",
        "        ax.set_ylim([0.85, 1.0])\n",
        "        ax.grid(axis='y', alpha=0.3)\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # 6. Compara√ß√£o lado a lado\n",
        "        ax = axes[1, 2]\n",
        "        metricas_principais = self.df_comparacao[['T√©cnica', 'Acur√°cia', 'Macro F1-Score',\n",
        "                                                   'Macro Precision', 'Macro Recall']].set_index('T√©cnica')\n",
        "        metricas_principais.plot(kind='bar', ax=ax, width=0.8)\n",
        "        ax.set_title('Todas as M√©tricas', fontsize=14, fontweight='bold')\n",
        "        ax.set_ylabel('Score', fontsize=12)\n",
        "        ax.set_xlabel('')\n",
        "        ax.set_ylim([0.85, 1.0])\n",
        "        ax.legend(loc='lower right', fontsize=9)\n",
        "        ax.grid(axis='y', alpha=0.3)\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
        "        print(f\"   ‚úì Gr√°ficos salvos em: {output_file}\")\n",
        "        plt.close()\n",
        "\n",
        "    def visualizar_matrizes_confusao(self, output_file='matrizes_confusao.png'):\n",
        "        \"\"\"Cria visualiza√ß√£o das matrizes de confus√£o\"\"\"\n",
        "        print(f\"\\nGerando matrizes de confus√£o...\")\n",
        "\n",
        "        # Filtrar t√©cnicas v√°lidas\n",
        "        tecnicas_validas = {k: v for k, v in self.resultados_comparacao.items() if v is not None}\n",
        "        n_tecnicas = len(tecnicas_validas)\n",
        "\n",
        "        # Criar subplots\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "        fig.suptitle('Matrizes de Confus√£o - Compara√ß√£o de T√©cnicas',\n",
        "                     fontsize=16, fontweight='bold')\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for idx, (tecnica, metricas) in enumerate(tecnicas_validas.items()):\n",
        "            cm = metricas['Confusion Matrix']\n",
        "\n",
        "            # Calcular percentuais\n",
        "            cm_percentual = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
        "\n",
        "            # Plotar\n",
        "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
        "                       cbar=False, square=True, linewidths=2, linecolor='white',\n",
        "                       annot_kws={'size': 14, 'weight': 'bold'})\n",
        "\n",
        "            # Adicionar percentuais\n",
        "            for i in range(cm.shape[0]):\n",
        "                for j in range(cm.shape[1]):\n",
        "                    axes[idx].text(j + 0.5, i + 0.7, f'({cm_percentual[i, j]:.1f}%)',\n",
        "                                 ha='center', va='center', fontsize=10, color='gray')\n",
        "\n",
        "            axes[idx].set_title(f'{tecnica}\\nF1-Macro: {metricas[\"Macro F1-Score\"]:.4f}',\n",
        "                              fontsize=12, fontweight='bold')\n",
        "            axes[idx].set_ylabel('Classe Real', fontsize=11)\n",
        "            axes[idx].set_xlabel('Classe Predita', fontsize=11)\n",
        "\n",
        "            # Destacar melhor t√©cnica\n",
        "            if tecnica == self.melhor_tecnica:\n",
        "                for spine in axes[idx].spines.values():\n",
        "                    spine.set_edgecolor('gold')\n",
        "                    spine.set_linewidth(4)\n",
        "\n",
        "        # Remover subplots n√£o utilizados\n",
        "        for idx in range(n_tecnicas, len(axes)):\n",
        "            fig.delaxes(axes[idx])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
        "        print(f\"   ‚úì Matrizes de confus√£o salvas em: {output_file}\")\n",
        "        plt.close()\n",
        "\n",
        "    def analisar_metricas_por_classe(self):\n",
        "        \"\"\"Analisa m√©tricas detalhadas por classe\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 100)\n",
        "        print(\"AN√ÅLISE DETALHADA POR CLASSE\")\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "        # Comparar baseline vs melhor t√©cnica\n",
        "        baseline = self.resultados_comparacao['SEM Balanceamento']\n",
        "        melhor = self.resultados_comparacao[self.melhor_tecnica]\n",
        "\n",
        "        print(f\"\\nCompara√ß√£o: BASELINE vs {self.melhor_tecnica}\\n\")\n",
        "\n",
        "        # Criar tabela\n",
        "        classes = sorted(baseline['Report'].keys())\n",
        "        classes = [c for c in classes if c not in ['accuracy', 'macro avg', 'weighted avg']]\n",
        "\n",
        "        print(\"‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
        "        print(f\"‚îÇ Classe  ‚îÇ      SEM Balanceamento       ‚îÇ       {self.melhor_tecnica:^20s}       ‚îÇ\")\n",
        "        print(\"‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\")\n",
        "        print(\"‚îÇ         ‚îÇ  Prec   Recall   F1-Score    ‚îÇ  Prec   Recall   F1-Score    ‚îÇ\")\n",
        "        print(\"‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\")\n",
        "\n",
        "        for classe in classes:\n",
        "            base_metrics = baseline['Report'][str(classe)]\n",
        "            melhor_metrics = melhor['Report'][str(classe)]\n",
        "\n",
        "            print(f\"‚îÇ Classe {classe} ‚îÇ  {base_metrics['precision']:.3f}   {base_metrics['recall']:.3f}    {base_metrics['f1-score']:.3f}     ‚îÇ\" +\n",
        "                  f\"  {melhor_metrics['precision']:.3f}   {melhor_metrics['recall']:.3f}    {melhor_metrics['f1-score']:.3f}     ‚îÇ\")\n",
        "\n",
        "        print(\"‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
        "\n",
        "        # An√°lise de melhorias\n",
        "        print(\"\\nMELHORIAS POR CLASSE:\\n\")\n",
        "        for classe in classes:\n",
        "            base_f1 = baseline['Report'][str(classe)]['f1-score']\n",
        "            melhor_f1 = melhor['Report'][str(classe)]['f1-score']\n",
        "            melhoria = ((melhor_f1 - base_f1) / base_f1) * 100\n",
        "\n",
        "            seta = \"^\" if melhoria > 0 else \"\" if melhoria < 0 else \">\"\n",
        "            print(f\"   Classe {classe}: {seta} {melhoria:+.2f}% (de {base_f1:.4f} para {melhor_f1:.4f})\")\n",
        "\n",
        "    def gerar_relatorio_final(self, output_file='RELATORIO_AVALIACAO.txt'):\n",
        "        \"\"\"Gera relat√≥rio final completo\"\"\"\n",
        "        print(f\"\\nGerando relat√≥rio final...\")\n",
        "\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"=\" * 100 + \"\\n\")\n",
        "            f.write(\" \" * 25 + \"RELAT√ìRIO DE AVALIA√á√ÉO DO MODELO\\n\")\n",
        "            f.write(\" \" * 20 + \"An√°lise do Impacto do Desbalanceamento\\n\")\n",
        "            f.write(\"=\" * 100 + \"\\n\\n\")\n",
        "\n",
        "            # 1. INFORMA√á√ïES DO DATASET\n",
        "            f.write(\"1. INFORMA√á√ïES DO DATASET\\n\")\n",
        "            f.write(\"-\" * 100 + \"\\n\\n\")\n",
        "            f.write(f\"Total de Exemplos: {len(self.df)}\\n\")\n",
        "            f.write(f\"N√∫mero de Features: {self.X.shape[1]}\\n\")\n",
        "            f.write(f\"Target: {self.target_column}\\n\\n\")\n",
        "\n",
        "            # Distribui√ß√£o\n",
        "            contagem = self.y.value_counts().sort_index()\n",
        "            proporcoes = self.y.value_counts(normalize=True).sort_index() * 100\n",
        "\n",
        "            f.write(\"Distribui√ß√£o de Classes:\\n\")\n",
        "            for classe in contagem.index:\n",
        "                f.write(f\"  Classe {classe}: {contagem[classe]:5d} exemplos ({proporcoes[classe]:5.2f}%)\\n\")\n",
        "\n",
        "            f.write(f\"\\nRaz√£o de Desbalanceamento: {self.razao_desbalanceamento:.2f}:1\\n\")\n",
        "\n",
        "            # 2. IMPACTO DO DESBALANCEAMENTO\n",
        "            f.write(\"\\n\\n2. IMPACTO DO DESBALANCEAMENTO\\n\")\n",
        "            f.write(\"-\" * 100 + \"\\n\\n\")\n",
        "\n",
        "            baseline = self.resultados_comparacao['SEM Balanceamento']\n",
        "\n",
        "            f.write(\"MODELO SEM BALANCEAMENTO (Baseline):\\n\\n\")\n",
        "            f.write(f\"  ‚Ä¢ Acur√°cia:        {baseline['Acur√°cia']:.4f}\\n\")\n",
        "            f.write(f\"  ‚Ä¢ Macro F1-Score:  {baseline['Macro F1-Score']:.4f}\\n\")\n",
        "            f.write(f\"  ‚Ä¢ Macro Precision: {baseline['Macro Precision']:.4f}\\n\")\n",
        "            f.write(f\"  ‚Ä¢ Macro Recall:    {baseline['Macro Recall']:.4f}\\n\\n\")\n",
        "\n",
        "            f.write(\"PROBLEMAS IDENTIFICADOS:\\n\\n\")\n",
        "\n",
        "            # Analisar problemas\n",
        "            report = baseline['Report']\n",
        "            classes = [c for c in report.keys() if c not in ['accuracy', 'macro avg', 'weighted avg']]\n",
        "\n",
        "            # Identificar classe minorit√°ria\n",
        "            contagem = self.y.value_counts()\n",
        "            classe_minoritaria = str(contagem.idxmin())\n",
        "            classe_majoritaria = str(contagem.idxmax())\n",
        "\n",
        "            recall_min = report[classe_minoritaria]['recall']\n",
        "            recall_maj = report[classe_majoritaria]['recall']\n",
        "\n",
        "            if recall_min < recall_maj - 0.05:\n",
        "                f.write(f\"   Classe minorit√°ria ({classe_minoritaria}) com Recall significativamente menor\\n\")\n",
        "                f.write(f\"      Recall Classe {classe_minoritaria}: {recall_min:.4f}\\n\")\n",
        "                f.write(f\"      Recall Classe {classe_majoritaria}: {recall_maj:.4f}\\n\")\n",
        "                f.write(f\"      Diferen√ßa: {(recall_maj - recall_min):.4f}\\n\\n\")\n",
        "\n",
        "            f.write(\"  Modelo pode estar enviesado para a classe majorit√°ria\\n\")\n",
        "            f.write(\"  Acur√°cia alta pode ser enganosa devido ao desbalanceamento\\n\")\n",
        "            f.write(\"  Macro F1-Score √© mais confi√°vel que Acur√°cia neste caso\\n\")\n",
        "\n",
        "            # 3. T√âCNICAS APLICADAS\n",
        "            f.write(\"\\n\\n3. T√âCNICAS DE BALANCEAMENTO APLICADAS\\n\")\n",
        "            f.write(\"-\" * 100 + \"\\n\\n\")\n",
        "\n",
        "            f.write(\"Foram testadas 5 abordagens:\\n\\n\")\n",
        "\n",
        "            f.write(\"1. SEM Balanceamento (Baseline)\\n\")\n",
        "            f.write(\"   ‚Ä¢ Modelo treinado com dados originais desbalanceados\\n\")\n",
        "            f.write(\"   ‚Ä¢ Serve como refer√™ncia para medir melhorias\\n\\n\")\n",
        "\n",
        "            f.write(\"2. SMOTE (Synthetic Minority Over-sampling Technique)\\n\")\n",
        "            f.write(\"   ‚Ä¢ Cria exemplos sint√©ticos da classe minorit√°ria\\n\")\n",
        "            f.write(\"   ‚Ä¢ Gera novos pontos interpolando exemplos existentes\\n\")\n",
        "            f.write(\"   ‚Ä¢ Aumenta o tamanho do conjunto de treino\\n\\n\")\n",
        "\n",
        "            f.write(\"3. ADASYN (Adaptive Synthetic Sampling)\\n\")\n",
        "            f.write(\"   ‚Ä¢ Similar ao SMOTE, mas adaptativo\\n\")\n",
        "            f.write(\"   ‚Ä¢ Foca em gerar exemplos em regi√µes dif√≠ceis de classificar\\n\")\n",
        "            f.write(\"   ‚Ä¢ Mais sens√≠vel a outliers\\n\\n\")\n",
        "\n",
        "            f.write(\"4. SMOTE + Tomek Links\\n\")\n",
        "            f.write(\"   ‚Ä¢ Combina SMOTE com limpeza de fronteira\\n\")\n",
        "            f.write(\"   ‚Ä¢ Remove exemplos amb√≠guos ap√≥s sobre-amostragem\\n\")\n",
        "            f.write(\"   ‚Ä¢ Melhora a defini√ß√£o da fronteira de decis√£o\\n\\n\")\n",
        "\n",
        "            f.write(\"5. Under-Sampling Aleat√≥rio\\n\")\n",
        "            f.write(\"   ‚Ä¢ Remove aleatoriamente exemplos da classe majorit√°ria\\n\")\n",
        "            f.write(\"   ‚Ä¢ Reduz o tamanho do conjunto de treino\\n\")\n",
        "            f.write(\"   ‚Ä¢ Pode perder informa√ß√£o importante\\n\\n\")\n",
        "\n",
        "            # 4. RESULTADOS COMPARATIVOS\n",
        "            f.write(\"\\n4. RESULTADOS COMPARATIVOS\\n\")\n",
        "            f.write(\"-\" * 100 + \"\\n\\n\")\n",
        "\n",
        "            f.write(self.df_comparacao.to_string(index=False))\n",
        "            f.write(\"\\n\\n\")\n",
        "\n",
        "            # 5. MELHOR T√âCNICA\n",
        "            f.write(\"\\n5. MELHOR T√âCNICA IDENTIFICADA\\n\")\n",
        "            f.write(\"-\" * 100 + \"\\n\\n\")\n",
        "\n",
        "            melhor = self.resultados_comparacao[self.melhor_tecnica]\n",
        "            baseline_f1 = baseline['Macro F1-Score']\n",
        "            melhor_f1 = melhor['Macro F1-Score']\n",
        "            melhoria = ((melhor_f1 - baseline_f1) / baseline_f1) * 100\n",
        "\n",
        "            f.write(f\"T√âCNICA VENCEDORA: {self.melhor_tecnica}\\n\\n\")\n",
        "            f.write(f\"M√âTRICAS FINAIS:\\n\\n\")\n",
        "            f.write(f\"  ‚Ä¢ Acur√°cia:        {melhor['Acur√°cia']:.4f}\\n\")\n",
        "            f.write(f\"  ‚Ä¢ Macro F1-Score:  {melhor['Macro F1-Score']:.4f}\\n\")\n",
        "            f.write(f\"  ‚Ä¢ Macro Precision: {melhor['Macro Precision']:.4f}\\n\")\n",
        "            f.write(f\"  ‚Ä¢ Macro Recall:    {melhor['Macro Recall']:.4f}\\n\\n\")\n",
        "\n",
        "            f.write(f\"MELHORIA SOBRE BASELINE:\\n\\n\")\n",
        "            f.write(f\"  ‚Ä¢ Macro F1-Score:  +{melhoria:.2f}%\\n\")\n",
        "            f.write(f\"  ‚Ä¢ De {baseline_f1:.4f} para {melhor_f1:.4f}\\n\\n\")\n",
        "\n",
        "            # 6. MATRIZ DE CONFUS√ÉO\n",
        "            f.write(\"\\n6. MATRIZ DE CONFUS√ÉO - MELHOR T√âCNICA\\n\")\n",
        "            f.write(\"-\" * 100 + \"\\n\\n\")\n",
        "\n",
        "            cm = melhor['Confusion Matrix']\n",
        "            f.write(\"Matriz de Confus√£o:\\n\\n\")\n",
        "            f.write(str(cm))\n",
        "            f.write(\"\\n\\n\")\n",
        "\n",
        "            # An√°lise da matriz\n",
        "            f.write(\"INTERPRETA√á√ÉO:\\n\\n\")\n",
        "\n",
        "            # Para classifica√ß√£o bin√°ria\n",
        "            if cm.shape[0] == 2:\n",
        "                tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "                f.write(f\"  Verdadeiros Negativos (TN): {tn}\\n\")\n",
        "                f.write(f\"  Falsos Positivos (FP):      {fp}\\n\")\n",
        "                f.write(f\"  Falsos Negativos (FN):      {fn}\\n\")\n",
        "                f.write(f\"  Verdadeiros Positivos (TP): {tp}\\n\\n\")\n",
        "\n",
        "                # Calcular taxas\n",
        "                tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "                tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "                f.write(f\"  Taxa de Verdadeiros Positivos (Recall Classe 1): {tpr:.4f}\\n\")\n",
        "                f.write(f\"  Taxa de Verdadeiros Negativos (Recall Classe 0): {tnr:.4f}\\n\\n\")\n",
        "\n",
        "                if abs(tpr - tnr) < 0.05:\n",
        "                    f.write(\"  Modelo balanceado entre as classes\\n\")\n",
        "                else:\n",
        "                    f.write(\" Modelo ainda apresenta algum vi√©s\\n\")\n",
        "\n",
        "            # 7. AN√ÅLISE POR CLASSE\n",
        "            f.write(\"\\n\\n7. DESEMPENHO POR CLASSE\\n\")\n",
        "            f.write(\"-\" * 100 + \"\\n\\n\")\n",
        "\n",
        "            f.write(\"COMPARA√á√ÉO: Baseline vs Melhor T√©cnica\\n\\n\")\n",
        "\n",
        "            classes = [c for c in melhor['Report'].keys() if c not in ['accuracy', 'macro avg', 'weighted avg']]\n",
        "\n",
        "            for classe in classes:\n",
        "                base_metrics = baseline['Report'][str(classe)]\n",
        "                melhor_metrics = melhor['Report'][str(classe)]\n",
        "\n",
        "                f.write(f\"Classe {classe}:\\n\")\n",
        "                f.write(f\"  Baseline:      Precision={base_metrics['precision']:.4f}, \" +\n",
        "                       f\"Recall={base_metrics['recall']:.4f}, F1={base_metrics['f1-score']:.4f}\\n\")\n",
        "                f.write(f\"  {self.melhor_tecnica}: Precision={melhor_metrics['precision']:.4f}, \" +\n",
        "                       f\"Recall={melhor_metrics['recall']:.4f}, F1={melhor_metrics['f1-score']:.4f}\\n\")\n",
        "\n",
        "                melhoria_f1 = ((melhor_metrics['f1-score'] - base_metrics['f1-score']) /\n",
        "                              base_metrics['f1-score']) * 100\n",
        "                f.write(f\"  Melhoria F1:   {melhoria_f1:+.2f}%\\n\\n\")\n",
        "\n",
        "            # 8. CONCLUS√ïES\n",
        "            f.write(\"\\n8. CONCLUS√ïES E RECOMENDA√á√ïES\\n\")\n",
        "            f.write(\"-\" * 100 + \"\\n\\n\")\n",
        "\n",
        "            f.write(\"PRINCIPAIS DESCOBERTAS:\\n\\n\")\n",
        "\n",
        "            f.write(f\"1. O dataset apresenta desbalanceamento {self.razao_desbalanceamento:.2f}:1\\n\\n\")\n",
        "\n",
        "            f.write(f\"2. O uso de {self.melhor_tecnica} melhorou significativamente o desempenho:\\n\")\n",
        "            f.write(f\"   ‚Ä¢ Macro F1-Score aumentou em {melhoria:.2f}%\\n\")\n",
        "            f.write(f\"   ‚Ä¢ Modelo ficou mais balanceado entre as classes\\n\\n\")\n",
        "\n",
        "            f.write(\"3. M√©tricas adequadas para dados desbalanceados:\\n\")\n",
        "            f.write(\"   ‚Ä¢ Macro F1-Score √© a m√©trica principal (equilibra precis√£o e recall)\\n\")\n",
        "            f.write(\"   ‚Ä¢ Matriz de Confus√£o revela padr√µes de erro por classe\\n\")\n",
        "            f.write(\"   ‚Ä¢ Acur√°cia sozinha pode ser enganosa\\n\\n\")\n",
        "\n",
        "            f.write(\"RECOMENDA√á√ïES:\\n\\n\")\n",
        "            f.write(f\"‚Ä¢ Utilizar {self.melhor_tecnica} para treinar o modelo final\\n\")\n",
        "            f.write(\"‚Ä¢ Monitorar Macro F1-Score como m√©trica principal\\n\")\n",
        "            f.write(\"‚Ä¢ Analisar a Matriz de Confus√£o regularmente\\n\")\n",
        "            f.write(\"‚Ä¢ Considerar ajuste de hiperpar√¢metros para melhorias adicionais\\n\")\n",
        "\n",
        "            f.write(\"\\n\" + \"=\" * 100 + \"\\n\")\n",
        "            f.write(\"RELAT√ìRIO GERADO COM SUCESSO\\n\")\n",
        "            f.write(\"=\" * 100 + \"\\n\")\n",
        "\n",
        "        print(f\"   ‚úì Relat√≥rio salvo em: {output_file}\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    FILEPATH = 'datasample.csv'\n",
        "    TARGET_COLUMN = 'Class'\n",
        "\n",
        "    FEATURES_SELECIONADAS = [\n",
        "        'V14', 'V12', 'V4', 'V11', 'V10',\n",
        "        'V16', 'V17', 'V3', 'V9', 'V7'\n",
        "    ]\n",
        "\n",
        "    MODELO = 'Random Forest'\n",
        "\n",
        "    try:\n",
        "        # 1. Inicializar avalia√ß√£o\n",
        "        avaliacao = AvaliacaoCompleta(\n",
        "            filepath=FILEPATH,\n",
        "            target_column=TARGET_COLUMN,\n",
        "            features_selecionadas=FEATURES_SELECIONADAS\n",
        "        )\n",
        "\n",
        "        # 2. Comparar t√©cnicas de balanceamento\n",
        "        resultados = avaliacao.comparar_tecnicas_balanceamento(\n",
        "            modelo_nome=MODELO,\n",
        "            features_selecionadas=FEATURES_SELECIONADAS\n",
        "        )\n",
        "\n",
        "        # 3. Gerar tabela comparativa\n",
        "        df_comparacao = avaliacao.gerar_tabela_comparativa()\n",
        "\n",
        "        # 4. Visualiza√ß√µes\n",
        "        avaliacao.visualizar_comparacao('comparacao_tecnicas.png')\n",
        "        avaliacao.visualizar_matrizes_confusao('matrizes_confusao.png')\n",
        "\n",
        "        # 5. An√°lise por classe\n",
        "        avaliacao.analisar_metricas_por_classe()\n",
        "\n",
        "        # 6. Relat√≥rio final\n",
        "        avaliacao.gerar_relatorio_final('RELATORIO_AVALIACAO.txt')\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 100)\n",
        "        print(\"AVALIA√á√ÉO COMPLETA CONCLU√çDA COM SUCESSO!\")\n",
        "        print(\"=\" * 100)\n",
        "        print(\"\\nArquivos gerados:\")\n",
        "        print(\"   ‚Ä¢ RELATORIO_AVALIACAO.txt - Relat√≥rio completo\")\n",
        "        print(\"   ‚Ä¢ comparacao_tecnicas.png - Gr√°ficos comparativos\")\n",
        "        print(\"   ‚Ä¢ matrizes_confusao.png   - Matrizes de confus√£o\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nERRO: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    }
  ]
}
